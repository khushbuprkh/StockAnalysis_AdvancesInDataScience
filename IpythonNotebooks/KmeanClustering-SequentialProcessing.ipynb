{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Function for the Neural Network Done\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import plotly\n",
    "import itertools\n",
    "from talib.abstract import *\n",
    "import os\n",
    "import sys\n",
    " \n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.externals import joblib\n",
    "print(\"Import Function for the Neural Network Done\")\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "# import plotly.plotly as py\n",
    "# from plotly.graph_objs import *\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# import plotly.graph_objs as go\n",
    "# plotly.tools.set_credentials_file(username='maiti.t', api_key='km8Kdfszic1Cu6ZAWiZJ')\n",
    "# plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'NeuralNetworkModel.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_open_normalised_prices(df, start, end):\n",
    "    \n",
    "    print('************************************************************************')\n",
    "    df1 = pd.DataFrame(df[\"High\"]/df[\"Open\"])\n",
    "    df1.columns=[\"H/O\"]\n",
    "    df1[\"L/O\"] = df[\"Low\"]/df[\"Open\"]\n",
    "    df1[\"C/O\"] = df[\"Close\"]/df[\"Open\"]\n",
    " \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_follow_cluster_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_follow_cluster_matrix(data):\n",
    "    print('************************************************************************')\n",
    "    data[\"ClusterTomorrow\"] = data[\"Cluster\"].shift(-1)\n",
    "    data.dropna(inplace=True)\n",
    "    data[\"ClusterTomorrow\"] = data[\"ClusterTomorrow\"].apply(int)\n",
    "#     print(\"Tesssssssssssttttttttttttttt\")\n",
    "#     print(zip(data[\"Cluster\"], data[\"ClusterTomorrow\"]))\n",
    "    data[\"ClusterMatrix\"] = list(zip(data[\"Cluster\"], data[\"ClusterTomorrow\"]))\n",
    "    cmvc = data[\"ClusterMatrix\"].value_counts()\n",
    "    clust_mat = np.zeros( (k, k) )\n",
    "    for row in cmvc.iteritems():\n",
    "#         print(row[1]*100.0/len(data))\n",
    "        clust_mat[row[0]] = row[1]*100.0/len(data)\n",
    "    print(\"Cluster Follow-on Matrix:\")\n",
    "    print(clust_mat)\n",
    "    return clust_mat,cmvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_indicators(stocks, period):\n",
    "#     for i in stocks:\n",
    "        print(\"***********************************************************************\")\n",
    "        stocks.columns = [s.lower() for s in stocks.columns]\n",
    "        print(\"Adding Features: Started  \")\n",
    "        features = pd.DataFrame(SMA(stocks, timeperiod=10))\n",
    "        features.columns = ['sma_10']\n",
    "        features['NATR']=pd.DataFrame(NATR(stocks, timeperiod=14))\n",
    "        features = pd.concat([features,STOCHF(stocks, fastk_period=14, fastd_period=3)], axis=1)\n",
    "        features['willr'] = pd.DataFrame(WILLR(stocks, timeperiod=14))\n",
    "        features['rsi'] = pd.DataFrame(RSI(stocks, timeperiod=14))\n",
    "        features['wma_10'] = pd.DataFrame(WMA(stocks,10))\n",
    "        features['T3'] =pd.DataFrame(T3(stocks, timeperiod=5, vfactor=0))\n",
    "        features['closePrice']=pd.DataFrame(stocks['close'].shift(-period))\n",
    "        features['return_pct_change'] = ROC(stocks, timeperiod=period)\n",
    "        features['return_pct_change'] = features['return_pct_change'].shift(-period)\n",
    "        features['pct_change'] = features['return_pct_change'].apply(lambda x: '1' if x > 0 else '0' if x <= 0 else np.nan)\n",
    "        features = features.dropna()\n",
    "           \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modellingNeuralNetwork(trainX,trainY,numbFeatures,i):\n",
    "    print(\"Creating Neural Network .....\")\n",
    "    starttime= time.time()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=numbFeatures, activation='relu'))\n",
    "    model.add(Dense(11, input_dim=numbFeatures, activation='relu'))\n",
    "    model.add(Dense(11, input_dim=numbFeatures, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae', 'mape'])\n",
    "    history1 = model.fit(trainX, trainY, epochs=20, batch_size=2, verbose=0)\n",
    "    print(\"Time Taken to Model %s seconds ---\" % (time.time() - starttime))\n",
    "    print(\"*******************************************\")\n",
    "    print(history1)\n",
    "    print(\"*******************************************\")\n",
    "    scores = model.evaluate(trainX,trainY,verbose = 0)\n",
    "#     scores = model.evaluate(X, Y, verbose=0)\n",
    "#     print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[1]*100))\n",
    "    print(model.summary())\n",
    "#     picklefilename = 'model'+str(i)+'.pkl'\n",
    "#     joblib.dump(model, picklefilename)\n",
    "#     joblib.dump(model, 'model'+str(i)+'.pkl')\n",
    "\n",
    "    return model,history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset1(datasetReal,i):\n",
    "    print(type(datasetReal))\n",
    "    xdataset = datasetReal.copy()\n",
    "    xdataset = xdataset[xdataset.columns[xdataset.columns !='closePrice']]\n",
    "    dataset = np.array(xdataset)\n",
    "    print(\"Total Number of features in trainig Dataset \"+ str(xdataset.columns.size))\n",
    "    dataX = [dataset[n] for n in range(len(dataset)-i)]\n",
    "    return np.array(dataX),xdataset.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictedClosePrice = []\n",
    "frameshistory=[]\n",
    "# model = []\n",
    "def testingModel1(inputClusterone):\n",
    "    \n",
    "\n",
    "        for i in range(1,4):\n",
    "            print(\"Training the Neural Network for next \"+ str(i)+\" Prediction\")\n",
    "            starttime= time.time() \n",
    "            \n",
    "            print(\"Copying the input Dataset \")\n",
    "            inputdata = inputClusterone.copy()\n",
    "            \n",
    "            print(\"Cheking Process ::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "            \n",
    "            dataset1 = get_indicators(inputClusterone,i)\n",
    "            if(i ==1):\n",
    "                testdata = dataset1.tail(1)\n",
    "                joblib.dump(testdata, 'testdata.pkl')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            print(inputdata.tail(5))\n",
    "            print(\"__________________________________________________\")\n",
    "            print(dataset1.tail(5))\n",
    "            \n",
    "            print(\" ::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "\n",
    "            print(\"Making The Training Dataset\")\n",
    "            traindataset = dataset1.head(len(dataset1)-2)\n",
    "\n",
    "            trainY = np.array(traindataset['closePrice'])[i:]\n",
    "            trainX, numbFeatures = create_dataset1(traindataset,i)\n",
    "            \n",
    "            m,h = modellingNeuralNetwork(trainX,trainY,numbFeatures,i)\n",
    "            \n",
    "#             f={\"models\":m}\n",
    "#             s = pickle.dumps( m, \"model\"+str(i)+\".pkl\" ) \n",
    "#             s = pickle.dumps(m) \n",
    "#             joblib.dump(s, 'model'+str(i)+'.pkl')\n",
    "            print(\"Model Saved\")\n",
    "#             joblib.dump(m, '\"model\"+str(i)+\".pkl\"') \n",
    "#             model.append(m)\n",
    "            \n",
    "            fullReport  = pd.DataFrame(h.history)\n",
    "            fullReport.to_csv(\"Day_\"+ str(i)+\" NN_PredictionModel.csv\")\n",
    "            finalMAPE=fullReport['mean_absolute_percentage_error'].tail(1)\n",
    "            finalLoss = fullReport['loss'].tail(1)\n",
    "            finalMAE = fullReport['mean_absolute_error'].tail(1)\n",
    "\n",
    "            finalreport = pd.DataFrame(finalMAPE)\n",
    "            finalreport.columns = ['MAPE']\n",
    "            finalreport['Loss']=finalLoss\n",
    "            finalreport['MAE']=finalMAE\n",
    "            finalreport.index = range(1,len(finalreport)+1)\n",
    "\n",
    "            frameshistory.append(finalreport)\n",
    "            print(finalreport)\n",
    "\n",
    "            print(\"Testing on the Latest Trade Data ...\")\n",
    "\n",
    "#             trainfeature=traindataset.tail(len(traindataset)-1)\n",
    "#             trainlabel= trainfeature['closePrice']\n",
    "\n",
    "#             prediction = m.predict(trainX)\n",
    "#             my_list = map(lambda x: x[0], prediction)\n",
    "#             traintestlabel = pd.Series(my_list)\n",
    "            testdata = joblib.load('testdata.pkl') \n",
    "#             testdata = dataset1.tail(1)\n",
    "#             testdata = testDataLatestTrade\n",
    "#             testexpectedlabel = testdata['closePrice']\n",
    "\n",
    "            xtest = testdata[testdata.columns[testdata.columns !='closePrice']]\n",
    "            print(\"-----------------------------------------\")\n",
    "            print(\"Test record Given\")\n",
    "            print(xtest)\n",
    "            print(\"----------------------------------\")\n",
    "            #############PREDICTION OF TEST DATA###############################\n",
    "            predictiontest = m.predict(np.array(xtest))\n",
    "            \n",
    "            \n",
    "            temp_list = map(lambda x: x[0], predictiontest)\n",
    "            testlabel = pd.Series(temp_list)\n",
    "            print(\"**********************************************************\")\n",
    "#             print(\"Excpected Close Price \"+ str( testexpectedlabel.values))\n",
    "            print(\"Predicted Close Price  \"+ str(testlabel[0]))\n",
    "#             predictedClosePrice.append(testlabel[0])\n",
    "            clf = joblib.load('predictedClosePrice.pkl') \n",
    "            clf.append(testlabel[0])\n",
    "            joblib.dump(clf, 'predictedClosePrice.pkl')\n",
    "            print(\"**********************************************************\")\n",
    "            print(\"Time Taken to Model %s seconds ---\" % (time.time() - starttime))\n",
    "            \n",
    "        print(\"Testing the Model Finished ...\")\n",
    "        allrecord = pd.concat(frameshistory)\n",
    "        allrecord.index = range(1,len(allrecord)+1)\n",
    "        print(\"Final Model Evaluation Scores \")\n",
    "        print(allrecord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datadownload(start,end):\n",
    "    dow = web.DataReader(\"^DJI\", \"yahoo\", start, end)\n",
    "    return dow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(dow_norm,k):\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(dow_norm)\n",
    "    labels = km.labels_\n",
    "    return labels,km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getinformationCluster(cmvc,km):\n",
    "    print(\"Ranking of Clusters \");\n",
    "    print(str(cmvc))\n",
    "    print('************************************************************************')\n",
    "    print(\"Centroid for the K Means Clusters \")\n",
    "    kmean = pd.DataFrame(km.cluster_centers_)\n",
    "    kmean.columns=['X','Y','Z']\n",
    "    print(kmean)\n",
    "    print('************************************************************************')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictCluster(km,dow_norm,cmvc,clust_mat):\n",
    "    print(\"Getting the Latest Trade OHLC Values for DOW 30 \") \n",
    "    testdoeN = dow_norm.copy()\n",
    "    print(\"*****************************************8\")\n",
    "#     print(testdoeN.tail(5))\n",
    "#     del testdoeN['Cluster']\n",
    "#     print(\"Testtttttt\")\n",
    "    \n",
    "    print(testdoeN.tail(1).values.reshape(-1,3))\n",
    "    predictedCluster = km.predict(testdoeN.tail(1).values.reshape(-1,3))[0]\n",
    "    print(\"Predicted Cluster of Last Trade OHLC Date \"+ \" \"+ str(testdoeN.index[len(testdoeN)-1])+\" \"+ str(predictedCluster))\n",
    "    predictedNextCluster = []\n",
    "    for i,row in cmvc.iteritems():\n",
    "        if(i[0]==predictedCluster):\n",
    "            predictedNextCluster.append(i[1])\n",
    "    print(\"Predicted Next Day Cluster would be : \"+ str(predictedNextCluster))\n",
    "    \n",
    "    probabCluster=[]\n",
    "    totalPrbablityfromPast=0\n",
    "    for i in predictedNextCluster:\n",
    "            totalPrbablityfromPast=totalPrbablityfromPast+clust_mat[predictedCluster][i]\n",
    "    #         probabCluster.append(clust_mat[predictedCluster][i])\n",
    "    print(\"Calulating the Relative Probablity \")\n",
    "    for i in predictedNextCluster:\n",
    "            probabCluster.append(clust_mat[predictedCluster][i]/totalPrbablityfromPast*100)\n",
    "            \n",
    "    nextClusterMatrix = pd.DataFrame(predictedNextCluster)\n",
    "    nextClusterMatrix.columns=[\"Cluster\"]\n",
    "    nextClusterMatrix['Probability']=probabCluster\n",
    "    \n",
    "    print(\"Next Day CLuster and its Relative probablity from the Predicted Cluster : \"+ str(predictedCluster))\n",
    "    print(nextClusterMatrix)\n",
    "    return nextClusterMatrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRightClusteredData(nextClusterMatrix,dowtrain):\n",
    "    print(\"Getting the filtered Past data where the maximum predicted range of the next DAY OHLC would be.. \")\n",
    "    inputClusterone = dowtrain[dowtrain['Cluster']==nextClusterMatrix['Cluster'][0]]\n",
    "    return inputClusterone\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas_datareader.data as web\n",
    "# start = datetime.datetime(2005, 1, 1)\n",
    "# end =  time.strftime(\"%Y-%m-%d\")\n",
    "# dow = web.DataReader(\"^DJI\", \"yahoo\", start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dow=pd.read_csv(\"AllDJIdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frameshistory=[]\n",
    "def testingModel(i):\n",
    "    \n",
    "\n",
    "#         for i in range(1,3):\n",
    "            print(\"Training the Neural Network for next \"+ str(i)+\" Prediction\")\n",
    "            starttime= time.time() \n",
    "            \n",
    "            print(\"Copying the input Dataset \")\n",
    "            inputdata = inputClusterone.copy()\n",
    "            \n",
    "            dataset1 = get_indicators(inputClusterone,i)\n",
    "\n",
    "            print(\"Making The Training Dataset\")\n",
    "            traindataset = dataset1.head(len(dataset1)-2)\n",
    "\n",
    "            trainY = np.array(traindataset['closePrice'])[i:]\n",
    "            trainX, numbFeatures = create_dataset1(traindataset,i)\n",
    "            \n",
    "            m,h = modellingNeuralNetwork(trainX,trainY,numbFeatures,i)\n",
    "            \n",
    "#             f={\"models\":m}\n",
    "#             s = pickle.dumps( m, \"model\"+str(i)+\".pkl\" ) \n",
    "#             s = pickle.dumps(m) \n",
    "            \n",
    "            print(\"Model Saved\")\n",
    "#             joblib.dump(m, '\"model\"+str(i)+\".pkl\"') \n",
    "#             model.append(m)\n",
    "            \n",
    "            fullReport  = pd.DataFrame(h.history)\n",
    "#             fullReport.to_csv(\"Day_\"+ str(i)+\" NN_PredictionModel.csv\")\n",
    "            finalMAPE=fullReport['mean_absolute_percentage_error'].tail(1)\n",
    "            finalLoss = fullReport['loss'].tail(1)\n",
    "            finalMAE = fullReport['mean_absolute_error'].tail(1)\n",
    "\n",
    "            finalreport = pd.DataFrame(finalMAPE)\n",
    "            finalreport.columns = ['MAPE']\n",
    "            finalreport['Loss']=finalLoss\n",
    "            finalreport['MAE']=finalMAE\n",
    "            finalreport.index = range(1,len(finalreport)+1)\n",
    "\n",
    "            frameshistory.append(finalreport)\n",
    "            print(finalreport)\n",
    "\n",
    "            print(\"Testing on the Latest Trade Data ...\")\n",
    "\n",
    "#             trainfeature=traindataset.tail(len(traindataset)-1)\n",
    "#             trainlabel= trainfeature['closePrice']\n",
    "\n",
    "#             prediction = m.predict(trainX)\n",
    "#             my_list = map(lambda x: x[0], prediction)\n",
    "#             traintestlabel = pd.Series(my_list)\n",
    "\n",
    "            testdata = dataset1.tail(1)\n",
    "#             testdata = testDataLatestTrade\n",
    "#             testexpectedlabel = testdata['closePrice']\n",
    "\n",
    "            xtest = testdata[testdata.columns[testdata.columns !='closePrice']]\n",
    "            ## Prediction###on Test Data ##########################################\n",
    "            predictiontest = m.predict(np.array(xtest))\n",
    "            \n",
    "            \n",
    "            temp_list = map(lambda x: x[0], predictiontest)\n",
    "            testlabel = pd.Series(temp_list)\n",
    "            print(\"**********************************************************\")\n",
    "#             print(\"Excpected Close Price \"+ str( testexpectedlabel.values))\n",
    "            print(\"Predicted Close Price  \"+ str(testlabel[0]))\n",
    "    \n",
    "            clf = joblib.load('predictedClosePrice.pkl') \n",
    "            clf.append(testlabel[0])\n",
    "            joblib.dump(clf, 'predictedClosePrice.pkl')\n",
    "#             predictedClosePrice.append(testlabel[0])\n",
    "            print(\"**********************************************************\")\n",
    "            print(\"Time Taken to Model %s seconds ---\" % (time.time() - starttime))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "Step 1:Downloading the DOW 30 data from Yahoo Finance \n",
      "Status ::Data Download Finish....\n",
      "************************************************************************\n",
      "Step 2:Normalising the Data with respect to Daily Open Stock Price \n",
      "************************************************************************\n",
      "Number of Chosen Cluster : 5 \n",
      "************************************************************************\n",
      "Step 3: KNN Process Started ...\n",
      "Status : KNN Process Finished ...\n",
      "************************************************************************\n",
      "Cluster Follow-on Matrix:\n",
      "[[  5.6675063    0.28337531   0.66120907   4.59697733  14.26322418]\n",
      " [  0.34634761   0.15743073   0.44080605   0.34634761   0.12594458]\n",
      " [  0.66120907   0.25188917   0.22040302   0.66120907   0.91309824]\n",
      " [  5.47858942   0.44080605   0.62972292   2.67632242   5.85642317]\n",
      " [ 13.3186398    0.28337531   0.75566751   6.80100756  34.16246851]]\n",
      "************************************************************************\n",
      "Ranking of Clusters \n",
      "(4, 4)    1085\n",
      "(0, 4)     453\n",
      "(4, 0)     423\n",
      "(4, 3)     216\n",
      "(3, 4)     186\n",
      "(0, 0)     180\n",
      "(3, 0)     174\n",
      "(0, 3)     146\n",
      "(3, 3)      85\n",
      "(2, 4)      29\n",
      "(4, 2)      24\n",
      "(2, 3)      21\n",
      "(2, 0)      21\n",
      "(0, 2)      21\n",
      "(3, 2)      20\n",
      "(1, 2)      14\n",
      "(3, 1)      14\n",
      "(1, 3)      11\n",
      "(1, 0)      11\n",
      "(4, 1)       9\n",
      "(0, 1)       9\n",
      "(2, 1)       8\n",
      "(2, 2)       7\n",
      "(1, 1)       5\n",
      "(1, 4)       4\n",
      "Name: ClusterMatrix, dtype: int64\n",
      "************************************************************************\n",
      "Centroid for the K Means Clusters \n",
      "          X         Y         Z\n",
      "0  1.011521  0.998466  1.008911\n",
      "1  1.003179  0.950500  0.958893\n",
      "2  1.035036  0.995937  1.031867\n",
      "3  1.002028  0.983354  0.987077\n",
      "4  1.003292  0.995590  0.999500\n",
      "************************************************************************\n",
      "Getting the Latest Trade OHLC Values for DOW 30 \n",
      "*****************************************8\n",
      "[[ 1.00040898  0.99734771  0.99859646]]\n",
      "Predicted Cluster of Last Trade OHLC Date  3176 4\n",
      "Predicted Next Day Cluster would be : [4, 0, 3, 2, 1]\n",
      "Calulating the Relative Probablity \n",
      "Next Day CLuster and its Relative probablity from the Predicted Cluster : 4\n",
      "   Cluster  Probability\n",
      "0        4    61.752988\n",
      "1        0    24.075128\n",
      "2        3    12.293682\n",
      "3        2     1.365965\n",
      "4        1     0.512237\n",
      "Getting the filtered Past data where the maximum predicted range of the next DAY OHLC would be.. \n",
      "Training the Neural Network for next 1 Prediction\n",
      "Copying the input Dataset \n",
      "Cheking Process ::::::::::::::::::::::::::::::::::::::::::::\n",
      "***********************************************************************\n",
      "Adding Features: Started  \n",
      "            Date          Open          High           Low         Close  \\\n",
      "3171  2017-08-08  22095.140625  22179.109375  22057.289063  22085.339844   \n",
      "3172  2017-08-09  22022.339844  22057.189453  21996.689453  22048.699219   \n",
      "3173  2017-08-10  21988.199219  21988.199219  21843.939453  21844.009766   \n",
      "3174  2017-08-11  21883.320313  21911.089844  21842.740234  21858.320313   \n",
      "3175  2017-08-14  21945.640625  22019.230469  21945.640625  21993.710938   \n",
      "\n",
      "         Adj Close     Volume  Cluster  ClusterTomorrow ClusterMatrix  \n",
      "3171  22085.339844  262000000        4                4        (4, 4)  \n",
      "3172  22048.699219  277800000        4                4        (4, 4)  \n",
      "3173  21844.009766  303310000        4                4        (4, 4)  \n",
      "3174  21858.320313  237790000        4                4        (4, 4)  \n",
      "3175  21993.710938  235030000        4                4        (4, 4)  \n",
      "__________________________________________________\n",
      "            sma_10      NATR      fastk      fastd      willr        rsi  \\\n",
      "3170  21905.991016  0.438776  99.563139  98.764977  -0.436861  77.912689   \n",
      "3171  21953.182031  0.447444  86.270501  95.277880 -13.729499  74.653150   \n",
      "3172  21986.950977  0.444893  80.905672  88.913104 -19.094328  71.104788   \n",
      "3173  21991.696875  0.483942  50.935556  72.703910 -49.064444  55.293391   \n",
      "3174  21994.497852  0.471415  46.689777  59.510335 -53.310223  56.029560   \n",
      "\n",
      "            wma_10            T3    closePrice  return_pct_change pct_change  \n",
      "3170  21987.771484  21849.845639  22085.339844          -0.149559          0  \n",
      "3171  22020.380362  21892.697324  22048.699219          -0.165905          0  \n",
      "3172  22037.747124  21929.292702  21844.009766          -0.928352          0  \n",
      "3173  22011.757813  21951.388042  21858.320313           0.065512          1  \n",
      "3174  21987.507529  21960.011700  21993.710938           0.619401          1  \n",
      " ::::::::::::::::::::::::::::::::::::::::::::\n",
      "Making The Training Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Total Number of features in trainig Dataset 10\n",
      "Creating Neural Network .....\n",
      "Time Taken to Model 20.7475140095 seconds ---\n",
      "*******************************************\n",
      "<keras.callbacks.History object at 0x7fc992ffb790>\n",
      "*******************************************\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 11)                66        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model Saved\n",
      "       MAPE          Loss         MAE\n",
      "1  1.477935  89280.921699  196.154799\n",
      "Testing on the Latest Trade Data ...\n",
      "-----------------------------------------\n",
      "Test record Given\n",
      "            sma_10      NATR      fastk      fastd      willr       rsi  \\\n",
      "3174  21994.497852  0.471415  46.689777  59.510335 -53.310223  56.02956   \n",
      "\n",
      "            wma_10          T3  return_pct_change pct_change  \n",
      "3174  21987.507529  21960.0117           0.619401          1  \n",
      "----------------------------------\n",
      "**********************************************************\n",
      "Predicted Close Price  21677.6679688\n",
      "**********************************************************\n",
      "Time Taken to Model 20.9134171009 seconds ---\n",
      "Training the Neural Network for next 2 Prediction\n",
      "Copying the input Dataset \n",
      "Cheking Process ::::::::::::::::::::::::::::::::::::::::::::\n",
      "***********************************************************************\n",
      "Adding Features: Started  \n",
      "            date          open          high           low         close  \\\n",
      "3171  2017-08-08  22095.140625  22179.109375  22057.289063  22085.339844   \n",
      "3172  2017-08-09  22022.339844  22057.189453  21996.689453  22048.699219   \n",
      "3173  2017-08-10  21988.199219  21988.199219  21843.939453  21844.009766   \n",
      "3174  2017-08-11  21883.320313  21911.089844  21842.740234  21858.320313   \n",
      "3175  2017-08-14  21945.640625  22019.230469  21945.640625  21993.710938   \n",
      "\n",
      "         adj close     volume  cluster  clustertomorrow clustermatrix  \n",
      "3171  22085.339844  262000000        4                4        (4, 4)  \n",
      "3172  22048.699219  277800000        4                4        (4, 4)  \n",
      "3173  21844.009766  303310000        4                4        (4, 4)  \n",
      "3174  21858.320313  237790000        4                4        (4, 4)  \n",
      "3175  21993.710938  235030000        4                4        (4, 4)  \n",
      "__________________________________________________\n",
      "            sma_10      NATR       fastk      fastd      willr        rsi  \\\n",
      "3169  21845.466016  0.459434  100.000000  97.738868  -0.000000  77.196960   \n",
      "3170  21905.991016  0.438776   99.563139  98.764977  -0.436861  77.912689   \n",
      "3171  21953.182031  0.447444   86.270501  95.277880 -13.729499  74.653150   \n",
      "3172  21986.950977  0.444893   80.905672  88.913104 -19.094328  71.104788   \n",
      "3173  21991.696875  0.483942   50.935556  72.703910 -49.064444  55.293391   \n",
      "\n",
      "            wma_10            T3    closePrice  return_pct_change pct_change  \n",
      "3169  21938.143501  21803.873909  22085.339844          -0.033815          0  \n",
      "3170  21987.771484  21849.845639  22048.699219          -0.315216          0  \n",
      "3171  22020.380362  21892.697324  21844.009766          -1.092716          0  \n",
      "3172  22037.747124  21929.292702  21858.320313          -0.863447          0  \n",
      "3173  22011.757813  21951.388042  21993.710938           0.685319          1  \n",
      " ::::::::::::::::::::::::::::::::::::::::::::\n",
      "Making The Training Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Total Number of features in trainig Dataset 10\n",
      "Creating Neural Network .....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to Model 21.0913958549 seconds ---\n",
      "*******************************************\n",
      "<keras.callbacks.History object at 0x7fc992c35390>\n",
      "*******************************************\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 11)                66        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model Saved\n",
      "      MAPE           Loss         MAE\n",
      "1  2.01197  149286.168834  267.864143\n",
      "Testing on the Latest Trade Data ...\n",
      "-----------------------------------------\n",
      "Test record Given\n",
      "            sma_10      NATR      fastk      fastd      willr       rsi  \\\n",
      "3174  21994.497852  0.471415  46.689777  59.510335 -53.310223  56.02956   \n",
      "\n",
      "            wma_10          T3  return_pct_change pct_change  \n",
      "3174  21987.507529  21960.0117           0.619401          1  \n",
      "----------------------------------\n",
      "**********************************************************\n",
      "Predicted Close Price  22137.4550781\n",
      "**********************************************************\n",
      "Time Taken to Model 21.2820248604 seconds ---\n",
      "Training the Neural Network for next 3 Prediction\n",
      "Copying the input Dataset \n",
      "Cheking Process ::::::::::::::::::::::::::::::::::::::::::::\n",
      "***********************************************************************\n",
      "Adding Features: Started  \n",
      "            date          open          high           low         close  \\\n",
      "3171  2017-08-08  22095.140625  22179.109375  22057.289063  22085.339844   \n",
      "3172  2017-08-09  22022.339844  22057.189453  21996.689453  22048.699219   \n",
      "3173  2017-08-10  21988.199219  21988.199219  21843.939453  21844.009766   \n",
      "3174  2017-08-11  21883.320313  21911.089844  21842.740234  21858.320313   \n",
      "3175  2017-08-14  21945.640625  22019.230469  21945.640625  21993.710938   \n",
      "\n",
      "         adj close     volume  cluster  clustertomorrow clustermatrix  \n",
      "3171  22085.339844  262000000        4                4        (4, 4)  \n",
      "3172  22048.699219  277800000        4                4        (4, 4)  \n",
      "3173  21844.009766  303310000        4                4        (4, 4)  \n",
      "3174  21858.320313  237790000        4                4        (4, 4)  \n",
      "3175  21993.710938  235030000        4                4        (4, 4)  \n",
      "__________________________________________________\n",
      "            sma_10      NATR       fastk      fastd      willr        rsi  \\\n",
      "3168  21794.191992  0.472466   96.731793  96.015515  -3.268207  75.257588   \n",
      "3169  21845.466016  0.459434  100.000000  97.738868  -0.000000  77.196960   \n",
      "3170  21905.991016  0.438776   99.563139  98.764977  -0.436861  77.912689   \n",
      "3171  21953.182031  0.447444   86.270501  95.277880 -13.729499  74.653150   \n",
      "3172  21986.950977  0.444893   80.905672  88.913104 -19.094328  71.104788   \n",
      "\n",
      "            wma_10            T3    closePrice  return_pct_change pct_change  \n",
      "3168  21883.849219  21758.160513  22085.339844           0.268955          1  \n",
      "3169  21938.143501  21803.873909  22048.699219          -0.199664          0  \n",
      "3170  21987.771484  21849.845639  21844.009766          -1.240641          0  \n",
      "3171  22020.380362  21892.697324  21858.320313          -1.027920          0  \n",
      "3172  22037.747124  21929.292702  21993.710938          -0.249395          0  \n",
      " ::::::::::::::::::::::::::::::::::::::::::::\n",
      "Making The Training Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Total Number of features in trainig Dataset 10\n",
      "Creating Neural Network .....\n",
      "Time Taken to Model 20.5679681301 seconds ---\n",
      "*******************************************\n",
      "<keras.callbacks.History object at 0x7fc9928e0e10>\n",
      "*******************************************\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 11)                66        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model Saved\n",
      "       MAPE           Loss         MAE\n",
      "1  2.287448  197619.909536  300.779687\n",
      "Testing on the Latest Trade Data ...\n",
      "-----------------------------------------\n",
      "Test record Given\n",
      "            sma_10      NATR      fastk      fastd      willr       rsi  \\\n",
      "3174  21994.497852  0.471415  46.689777  59.510335 -53.310223  56.02956   \n",
      "\n",
      "            wma_10          T3  return_pct_change pct_change  \n",
      "3174  21987.507529  21960.0117           0.619401          1  \n",
      "----------------------------------\n",
      "**********************************************************\n",
      "Predicted Close Price  22285.7578125\n",
      "**********************************************************\n",
      "Time Taken to Model 20.7890901566 seconds ---\n",
      "Testing the Model Finished ...\n",
      "Final Model Evaluation Scores \n",
      "       MAPE           Loss         MAE\n",
      "1  1.477935   89280.921699  196.154799\n",
      "2  2.011970  149286.168834  267.864143\n",
      "3  2.287448  197619.909536  300.779687\n",
      "###########################################################\n",
      "Total Time Taken to Model 63.1387171745 seconds ---\n",
      "###########################################################\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Obtain DOW 30  pricing data from Yahoo Finance\n",
    "    print('************************************************************************')\n",
    "    starttime= time.time()\n",
    "    print(\"Step 1:Downloading the DOW 30 data from Yahoo Finance \")\n",
    "    start = datetime.datetime(2005, 1, 1)\n",
    "    end =  time.strftime(\"%Y-%m-%d\")\n",
    "#     dow = web.DataReader(\"^DJI\", \"yahoo\", start, end)\n",
    "#     dow = datadownload(start,end)\n",
    "    print(\"Status ::Data Download Finish....\")\n",
    "    print('************************************************************************')\n",
    "    print(\"Step 2:Normalising the Data with respect to Daily Open Stock Price \")\n",
    "    \n",
    "    dow_norm = get_open_normalised_prices(dow, start, end)\n",
    "    print(\"Number of Chosen Cluster : 5 \")\n",
    "    \n",
    "    k = 5\n",
    "    print('************************************************************************')\n",
    "    print(\"Step 3: KNN Process Started ...\")\n",
    "    \n",
    "    # Deleting the last row from the KNN Dataset \n",
    "    traindowNorm = dow_norm.copy()\n",
    "    traindowNorm.drop(traindowNorm.index[len(traindowNorm)-1])\n",
    "    \n",
    "    # Reatining the latest Trade info as normalised one\n",
    "    testDataLatestTrade = dow_norm.tail(1)\n",
    "    \n",
    "    labels,km = knn(traindowNorm,k)\n",
    "    \n",
    "    dowtrain = dow.copy()\n",
    "    dowtrain.drop(dowtrain.index[len(dowtrain)-1])\n",
    "    dowtrain[\"Cluster\"] = labels\n",
    "    traindowNorm[\"Cluster\"] = labels\n",
    "    \n",
    "    print(\"Status : KNN Process Finished ...\")\n",
    "    # Create and output the cluster follow-on matrix\n",
    "    clust_mat,cmvc = create_follow_cluster_matrix(dowtrain)\n",
    "    \n",
    "    print('************************************************************************')\n",
    "    \n",
    "    getinformationCluster(cmvc,km)\n",
    "    \n",
    "    nextClusterMatrix = predictCluster(km,testDataLatestTrade,cmvc,clust_mat)\n",
    "    \n",
    "    inputClusterone = getRightClusteredData(nextClusterMatrix,dowtrain)\n",
    "    \n",
    "    inputClusterone.append(dow.tail(1))\n",
    "    \n",
    "    joblib.dump(predictedClosePrice, 'predictedClosePrice.pkl')\n",
    "#     p = Pool(20)\n",
    "# #     frameshistory=[]\n",
    "#     print(p.map(testingModel, range (1,4)))\n",
    "    testingModel1(inputClusterone) #sequential\n",
    "#     print(\"Testing the Model Finished ...\")\n",
    "#     allrecord = pd.concat(frameshistory)\n",
    "#     allrecord.index = range(1,len(allrecord)+1)\n",
    "#     print(\"Final Model Evaluation Scores \")\n",
    "#     print(allrecord)\n",
    "    print(\"###########################################################\")\n",
    "    print(\"Total Time Taken to Model %s seconds ---\" % (time.time() - starttime))\n",
    "    print(\"###########################################################\")\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('predictedClosePrice.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21677.66796875, 22137.455078125, 22285.7578125]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump( predictedClosePrice, open( \"model.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
